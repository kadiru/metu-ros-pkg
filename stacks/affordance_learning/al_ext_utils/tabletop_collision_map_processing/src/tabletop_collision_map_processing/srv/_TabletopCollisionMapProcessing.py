"""autogenerated by genpy from tabletop_collision_map_processing/TabletopCollisionMapProcessingRequest.msg. Do not edit."""
import sys
python3 = True if sys.hexversion > 0x03000000 else False
import genpy
import struct

import arm_navigation_msgs.msg
import tabletop_object_detector.msg
import geometry_msgs.msg
import sensor_msgs.msg
import std_msgs.msg
import household_objects_database_msgs.msg

class TabletopCollisionMapProcessingRequest(genpy.Message):
  _md5sum = "fe986e22908c7a2936a0cdf9f240d4a3"
  _type = "tabletop_collision_map_processing/TabletopCollisionMapProcessingRequest"
  _has_header = False #flag to mark the presence of a Header object
  _full_text = """






tabletop_object_detector/TabletopDetectionResult detection_result


bool reset_collision_models


bool reset_attached_models



string desired_frame


================================================================================
MSG: tabletop_object_detector/TabletopDetectionResult
# Contains all the information from one run of the tabletop detection node

# The information for the plane that has been detected
Table table

# The raw clusters detected in the scan 
sensor_msgs/PointCloud[] clusters

# The list of potential models that have been detected for each cluster
# An empty list will be returned for a cluster that has no recognition results at all
household_objects_database_msgs/DatabaseModelPoseList[] models

# For each cluster, the index of the list of models that was fit to that cluster
# keep in mind that multiple raw clusters can correspond to a single fit
int32[] cluster_model_indices

# Whether the detection has succeeded or failed
int32 NO_CLOUD_RECEIVED = 1
int32 NO_TABLE = 2
int32 OTHER_ERROR = 3
int32 SUCCESS = 4
int32 result

================================================================================
MSG: tabletop_object_detector/Table
# Informs that a planar table has been detected at a given location

# The pose gives you the transform that take you to the coordinate system
# of the table, with the origin somewhere in the table plane and the 
# z axis normal to the plane
geometry_msgs/PoseStamped pose

# These values give you the observed extents of the table, along x and y,
# in the table's own coordinate system (above)
# there is no guarantee that the origin of the table coordinate system is
# inside the boundary defined by these values. 
float32 x_min
float32 x_max
float32 y_min
float32 y_max

# There is no guarantee that the table does NOT extend further than these 
# values; this is just as far as we've observed it.


# Newer table definition as triangle mesh of convex hull (relative to pose)
arm_navigation_msgs/Shape convex_hull

================================================================================
MSG: geometry_msgs/PoseStamped
# A Pose with reference coordinate frame and timestamp
Header header
Pose pose

================================================================================
MSG: std_msgs/Header
# Standard metadata for higher-level stamped data types.
# This is generally used to communicate timestamped data 
# in a particular coordinate frame.
# 
# sequence ID: consecutively increasing ID 
uint32 seq
#Two-integer timestamp that is expressed as:
# * stamp.secs: seconds (stamp_secs) since epoch
# * stamp.nsecs: nanoseconds since stamp_secs
# time-handling sugar is provided by the client library
time stamp
#Frame this data is associated with
# 0: no frame
# 1: global frame
string frame_id

================================================================================
MSG: geometry_msgs/Pose
# A representation of pose in free space, composed of postion and orientation. 
Point position
Quaternion orientation

================================================================================
MSG: geometry_msgs/Point
# This contains the position of a point in free space
float64 x
float64 y
float64 z

================================================================================
MSG: geometry_msgs/Quaternion
# This represents an orientation in free space in quaternion form.

float64 x
float64 y
float64 z
float64 w

================================================================================
MSG: arm_navigation_msgs/Shape
byte SPHERE=0
byte BOX=1
byte CYLINDER=2
byte MESH=3

byte type


#### define sphere, box, cylinder ####
# the origin of each shape is considered at the shape's center

# for sphere
# radius := dimensions[0]

# for cylinder
# radius := dimensions[0]
# length := dimensions[1]
# the length is along the Z axis

# for box
# size_x := dimensions[0]
# size_y := dimensions[1]
# size_z := dimensions[2]
float64[] dimensions


#### define mesh ####

# list of triangles; triangle k is defined by tre vertices located
# at indices triangles[3k], triangles[3k+1], triangles[3k+2]
int32[] triangles
geometry_msgs/Point[] vertices

================================================================================
MSG: sensor_msgs/PointCloud
# This message holds a collection of 3d points, plus optional additional
# information about each point.

# Time of sensor data acquisition, coordinate frame ID.
Header header

# Array of 3d points. Each Point32 should be interpreted as a 3d point
# in the frame given in the header.
geometry_msgs/Point32[] points

# Each channel should have the same number of elements as points array,
# and the data in each channel should correspond 1:1 with each point.
# Channel names in common practice are listed in ChannelFloat32.msg.
ChannelFloat32[] channels

================================================================================
MSG: geometry_msgs/Point32
# This contains the position of a point in free space(with 32 bits of precision).
# It is recommeded to use Point wherever possible instead of Point32.  
# 
# This recommendation is to promote interoperability.  
#
# This message is designed to take up less space when sending
# lots of points at once, as in the case of a PointCloud.  

float32 x
float32 y
float32 z
================================================================================
MSG: sensor_msgs/ChannelFloat32
# This message is used by the PointCloud message to hold optional data
# associated with each point in the cloud. The length of the values
# array should be the same as the length of the points array in the
# PointCloud, and each value should be associated with the corresponding
# point.

# Channel names in existing practice include:
#   "u", "v" - row and column (respectively) in the left stereo image.
#              This is opposite to usual conventions but remains for
#              historical reasons. The newer PointCloud2 message has no
#              such problem.
#   "rgb" - For point clouds produced by color stereo cameras. uint8
#           (R,G,B) values packed into the least significant 24 bits,
#           in order.
#   "intensity" - laser or pixel intensity.
#   "distance"

# The channel name should give semantics of the channel (e.g.
# "intensity" instead of "value").
string name

# The values array should be 1-1 with the elements of the associated
# PointCloud.
float32[] values

================================================================================
MSG: household_objects_database_msgs/DatabaseModelPoseList
# stores a list of possible database models recognition results
DatabaseModelPose[] model_list
================================================================================
MSG: household_objects_database_msgs/DatabaseModelPose
# Informs that a specific model from the Model Database has been 
# identified at a certain location

# the database id of the model
int32 model_id

# the pose that it can be found in
geometry_msgs/PoseStamped pose

# a measure of the confidence level in this detection result
float32 confidence

# the name of the object detector that generated this detection result
string detector_name

"""
  __slots__ = ['detection_result','reset_collision_models','reset_attached_models','desired_frame']
  _slot_types = ['tabletop_object_detector/TabletopDetectionResult','bool','bool','string']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.

    The available fields are:
       detection_result,reset_collision_models,reset_attached_models,desired_frame

    :param args: complete set of field values, in .msg order
    :param kwds: use keyword arguments corresponding to message field names
    to set specific fields.
    """
    if args or kwds:
      super(TabletopCollisionMapProcessingRequest, self).__init__(*args, **kwds)
      #message fields cannot be None, assign default values for those that are
      if self.detection_result is None:
        self.detection_result = tabletop_object_detector.msg.TabletopDetectionResult()
      if self.reset_collision_models is None:
        self.reset_collision_models = False
      if self.reset_attached_models is None:
        self.reset_attached_models = False
      if self.desired_frame is None:
        self.desired_frame = ''
    else:
      self.detection_result = tabletop_object_detector.msg.TabletopDetectionResult()
      self.reset_collision_models = False
      self.reset_attached_models = False
      self.desired_frame = ''

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    :param buff: buffer, ``StringIO``
    """
    try:
      _x = self
      buff.write(_struct_3I.pack(_x.detection_result.table.pose.header.seq, _x.detection_result.table.pose.header.stamp.secs, _x.detection_result.table.pose.header.stamp.nsecs))
      _x = self.detection_result.table.pose.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_7d4fb.pack(_x.detection_result.table.pose.pose.position.x, _x.detection_result.table.pose.pose.position.y, _x.detection_result.table.pose.pose.position.z, _x.detection_result.table.pose.pose.orientation.x, _x.detection_result.table.pose.pose.orientation.y, _x.detection_result.table.pose.pose.orientation.z, _x.detection_result.table.pose.pose.orientation.w, _x.detection_result.table.x_min, _x.detection_result.table.x_max, _x.detection_result.table.y_min, _x.detection_result.table.y_max, _x.detection_result.table.convex_hull.type))
      length = len(self.detection_result.table.convex_hull.dimensions)
      buff.write(_struct_I.pack(length))
      pattern = '<%sd'%length
      buff.write(struct.pack(pattern, *self.detection_result.table.convex_hull.dimensions))
      length = len(self.detection_result.table.convex_hull.triangles)
      buff.write(_struct_I.pack(length))
      pattern = '<%si'%length
      buff.write(struct.pack(pattern, *self.detection_result.table.convex_hull.triangles))
      length = len(self.detection_result.table.convex_hull.vertices)
      buff.write(_struct_I.pack(length))
      for val1 in self.detection_result.table.convex_hull.vertices:
        _x = val1
        buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
      length = len(self.detection_result.clusters)
      buff.write(_struct_I.pack(length))
      for val1 in self.detection_result.clusters:
        _v1 = val1.header
        buff.write(_struct_I.pack(_v1.seq))
        _v2 = _v1.stamp
        _x = _v2
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v1.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        length = len(val1.points)
        buff.write(_struct_I.pack(length))
        for val2 in val1.points:
          _x = val2
          buff.write(_struct_3f.pack(_x.x, _x.y, _x.z))
        length = len(val1.channels)
        buff.write(_struct_I.pack(length))
        for val2 in val1.channels:
          _x = val2.name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          length = len(val2.values)
          buff.write(_struct_I.pack(length))
          pattern = '<%sf'%length
          buff.write(struct.pack(pattern, *val2.values))
      length = len(self.detection_result.models)
      buff.write(_struct_I.pack(length))
      for val1 in self.detection_result.models:
        length = len(val1.model_list)
        buff.write(_struct_I.pack(length))
        for val2 in val1.model_list:
          buff.write(_struct_i.pack(val2.model_id))
          _v3 = val2.pose
          _v4 = _v3.header
          buff.write(_struct_I.pack(_v4.seq))
          _v5 = _v4.stamp
          _x = _v5
          buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
          _x = _v4.frame_id
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          _v6 = _v3.pose
          _v7 = _v6.position
          _x = _v7
          buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
          _v8 = _v6.orientation
          _x = _v8
          buff.write(_struct_4d.pack(_x.x, _x.y, _x.z, _x.w))
          buff.write(_struct_f.pack(val2.confidence))
          _x = val2.detector_name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
      length = len(self.detection_result.cluster_model_indices)
      buff.write(_struct_I.pack(length))
      pattern = '<%si'%length
      buff.write(struct.pack(pattern, *self.detection_result.cluster_model_indices))
      _x = self
      buff.write(_struct_i2B.pack(_x.detection_result.result, _x.reset_collision_models, _x.reset_attached_models))
      _x = self.desired_frame
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x))
    except struct.error as se: self._check_types(se)
    except TypeError as te: self._check_types(te)

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    :param str: byte array of serialized message, ``str``
    """
    try:
      if self.detection_result is None:
        self.detection_result = tabletop_object_detector.msg.TabletopDetectionResult()
      end = 0
      _x = self
      start = end
      end += 12
      (_x.detection_result.table.pose.header.seq, _x.detection_result.table.pose.header.stamp.secs, _x.detection_result.table.pose.header.stamp.nsecs,) = _struct_3I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.detection_result.table.pose.header.frame_id = str[start:end].decode('utf-8')
      else:
        self.detection_result.table.pose.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 73
      (_x.detection_result.table.pose.pose.position.x, _x.detection_result.table.pose.pose.position.y, _x.detection_result.table.pose.pose.position.z, _x.detection_result.table.pose.pose.orientation.x, _x.detection_result.table.pose.pose.orientation.y, _x.detection_result.table.pose.pose.orientation.z, _x.detection_result.table.pose.pose.orientation.w, _x.detection_result.table.x_min, _x.detection_result.table.x_max, _x.detection_result.table.y_min, _x.detection_result.table.y_max, _x.detection_result.table.convex_hull.type,) = _struct_7d4fb.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%sd'%length
      start = end
      end += struct.calcsize(pattern)
      self.detection_result.table.convex_hull.dimensions = struct.unpack(pattern, str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%si'%length
      start = end
      end += struct.calcsize(pattern)
      self.detection_result.table.convex_hull.triangles = struct.unpack(pattern, str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.detection_result.table.convex_hull.vertices = []
      for i in range(0, length):
        val1 = geometry_msgs.msg.Point()
        _x = val1
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
        self.detection_result.table.convex_hull.vertices.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.detection_result.clusters = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointCloud()
        _v9 = val1.header
        start = end
        end += 4
        (_v9.seq,) = _struct_I.unpack(str[start:end])
        _v10 = _v9.stamp
        _x = _v10
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v9.frame_id = str[start:end].decode('utf-8')
        else:
          _v9.frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.points = []
        for i in range(0, length):
          val2 = geometry_msgs.msg.Point32()
          _x = val2
          start = end
          end += 12
          (_x.x, _x.y, _x.z,) = _struct_3f.unpack(str[start:end])
          val1.points.append(val2)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.channels = []
        for i in range(0, length):
          val2 = sensor_msgs.msg.ChannelFloat32()
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val2.name = str[start:end].decode('utf-8')
          else:
            val2.name = str[start:end]
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          pattern = '<%sf'%length
          start = end
          end += struct.calcsize(pattern)
          val2.values = struct.unpack(pattern, str[start:end])
          val1.channels.append(val2)
        self.detection_result.clusters.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.detection_result.models = []
      for i in range(0, length):
        val1 = household_objects_database_msgs.msg.DatabaseModelPoseList()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.model_list = []
        for i in range(0, length):
          val2 = household_objects_database_msgs.msg.DatabaseModelPose()
          start = end
          end += 4
          (val2.model_id,) = _struct_i.unpack(str[start:end])
          _v11 = val2.pose
          _v12 = _v11.header
          start = end
          end += 4
          (_v12.seq,) = _struct_I.unpack(str[start:end])
          _v13 = _v12.stamp
          _x = _v13
          start = end
          end += 8
          (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            _v12.frame_id = str[start:end].decode('utf-8')
          else:
            _v12.frame_id = str[start:end]
          _v14 = _v11.pose
          _v15 = _v14.position
          _x = _v15
          start = end
          end += 24
          (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
          _v16 = _v14.orientation
          _x = _v16
          start = end
          end += 32
          (_x.x, _x.y, _x.z, _x.w,) = _struct_4d.unpack(str[start:end])
          start = end
          end += 4
          (val2.confidence,) = _struct_f.unpack(str[start:end])
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val2.detector_name = str[start:end].decode('utf-8')
          else:
            val2.detector_name = str[start:end]
          val1.model_list.append(val2)
        self.detection_result.models.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%si'%length
      start = end
      end += struct.calcsize(pattern)
      self.detection_result.cluster_model_indices = struct.unpack(pattern, str[start:end])
      _x = self
      start = end
      end += 6
      (_x.detection_result.result, _x.reset_collision_models, _x.reset_attached_models,) = _struct_i2B.unpack(str[start:end])
      self.reset_collision_models = bool(self.reset_collision_models)
      self.reset_attached_models = bool(self.reset_attached_models)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.desired_frame = str[start:end].decode('utf-8')
      else:
        self.desired_frame = str[start:end]
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e) #most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    :param buff: buffer, ``StringIO``
    :param numpy: numpy python module
    """
    try:
      _x = self
      buff.write(_struct_3I.pack(_x.detection_result.table.pose.header.seq, _x.detection_result.table.pose.header.stamp.secs, _x.detection_result.table.pose.header.stamp.nsecs))
      _x = self.detection_result.table.pose.header.frame_id
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x))
      _x = self
      buff.write(_struct_7d4fb.pack(_x.detection_result.table.pose.pose.position.x, _x.detection_result.table.pose.pose.position.y, _x.detection_result.table.pose.pose.position.z, _x.detection_result.table.pose.pose.orientation.x, _x.detection_result.table.pose.pose.orientation.y, _x.detection_result.table.pose.pose.orientation.z, _x.detection_result.table.pose.pose.orientation.w, _x.detection_result.table.x_min, _x.detection_result.table.x_max, _x.detection_result.table.y_min, _x.detection_result.table.y_max, _x.detection_result.table.convex_hull.type))
      length = len(self.detection_result.table.convex_hull.dimensions)
      buff.write(_struct_I.pack(length))
      pattern = '<%sd'%length
      buff.write(self.detection_result.table.convex_hull.dimensions.tostring())
      length = len(self.detection_result.table.convex_hull.triangles)
      buff.write(_struct_I.pack(length))
      pattern = '<%si'%length
      buff.write(self.detection_result.table.convex_hull.triangles.tostring())
      length = len(self.detection_result.table.convex_hull.vertices)
      buff.write(_struct_I.pack(length))
      for val1 in self.detection_result.table.convex_hull.vertices:
        _x = val1
        buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
      length = len(self.detection_result.clusters)
      buff.write(_struct_I.pack(length))
      for val1 in self.detection_result.clusters:
        _v17 = val1.header
        buff.write(_struct_I.pack(_v17.seq))
        _v18 = _v17.stamp
        _x = _v18
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v17.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        length = len(val1.points)
        buff.write(_struct_I.pack(length))
        for val2 in val1.points:
          _x = val2
          buff.write(_struct_3f.pack(_x.x, _x.y, _x.z))
        length = len(val1.channels)
        buff.write(_struct_I.pack(length))
        for val2 in val1.channels:
          _x = val2.name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          length = len(val2.values)
          buff.write(_struct_I.pack(length))
          pattern = '<%sf'%length
          buff.write(val2.values.tostring())
      length = len(self.detection_result.models)
      buff.write(_struct_I.pack(length))
      for val1 in self.detection_result.models:
        length = len(val1.model_list)
        buff.write(_struct_I.pack(length))
        for val2 in val1.model_list:
          buff.write(_struct_i.pack(val2.model_id))
          _v19 = val2.pose
          _v20 = _v19.header
          buff.write(_struct_I.pack(_v20.seq))
          _v21 = _v20.stamp
          _x = _v21
          buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
          _x = _v20.frame_id
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          _v22 = _v19.pose
          _v23 = _v22.position
          _x = _v23
          buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
          _v24 = _v22.orientation
          _x = _v24
          buff.write(_struct_4d.pack(_x.x, _x.y, _x.z, _x.w))
          buff.write(_struct_f.pack(val2.confidence))
          _x = val2.detector_name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
      length = len(self.detection_result.cluster_model_indices)
      buff.write(_struct_I.pack(length))
      pattern = '<%si'%length
      buff.write(self.detection_result.cluster_model_indices.tostring())
      _x = self
      buff.write(_struct_i2B.pack(_x.detection_result.result, _x.reset_collision_models, _x.reset_attached_models))
      _x = self.desired_frame
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x))
    except struct.error as se: self._check_types(se)
    except TypeError as te: self._check_types(te)

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    :param str: byte array of serialized message, ``str``
    :param numpy: numpy python module
    """
    try:
      if self.detection_result is None:
        self.detection_result = tabletop_object_detector.msg.TabletopDetectionResult()
      end = 0
      _x = self
      start = end
      end += 12
      (_x.detection_result.table.pose.header.seq, _x.detection_result.table.pose.header.stamp.secs, _x.detection_result.table.pose.header.stamp.nsecs,) = _struct_3I.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.detection_result.table.pose.header.frame_id = str[start:end].decode('utf-8')
      else:
        self.detection_result.table.pose.header.frame_id = str[start:end]
      _x = self
      start = end
      end += 73
      (_x.detection_result.table.pose.pose.position.x, _x.detection_result.table.pose.pose.position.y, _x.detection_result.table.pose.pose.position.z, _x.detection_result.table.pose.pose.orientation.x, _x.detection_result.table.pose.pose.orientation.y, _x.detection_result.table.pose.pose.orientation.z, _x.detection_result.table.pose.pose.orientation.w, _x.detection_result.table.x_min, _x.detection_result.table.x_max, _x.detection_result.table.y_min, _x.detection_result.table.y_max, _x.detection_result.table.convex_hull.type,) = _struct_7d4fb.unpack(str[start:end])
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%sd'%length
      start = end
      end += struct.calcsize(pattern)
      self.detection_result.table.convex_hull.dimensions = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=length)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%si'%length
      start = end
      end += struct.calcsize(pattern)
      self.detection_result.table.convex_hull.triangles = numpy.frombuffer(str[start:end], dtype=numpy.int32, count=length)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.detection_result.table.convex_hull.vertices = []
      for i in range(0, length):
        val1 = geometry_msgs.msg.Point()
        _x = val1
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
        self.detection_result.table.convex_hull.vertices.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.detection_result.clusters = []
      for i in range(0, length):
        val1 = sensor_msgs.msg.PointCloud()
        _v25 = val1.header
        start = end
        end += 4
        (_v25.seq,) = _struct_I.unpack(str[start:end])
        _v26 = _v25.stamp
        _x = _v26
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v25.frame_id = str[start:end].decode('utf-8')
        else:
          _v25.frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.points = []
        for i in range(0, length):
          val2 = geometry_msgs.msg.Point32()
          _x = val2
          start = end
          end += 12
          (_x.x, _x.y, _x.z,) = _struct_3f.unpack(str[start:end])
          val1.points.append(val2)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.channels = []
        for i in range(0, length):
          val2 = sensor_msgs.msg.ChannelFloat32()
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val2.name = str[start:end].decode('utf-8')
          else:
            val2.name = str[start:end]
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          pattern = '<%sf'%length
          start = end
          end += struct.calcsize(pattern)
          val2.values = numpy.frombuffer(str[start:end], dtype=numpy.float32, count=length)
          val1.channels.append(val2)
        self.detection_result.clusters.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.detection_result.models = []
      for i in range(0, length):
        val1 = household_objects_database_msgs.msg.DatabaseModelPoseList()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.model_list = []
        for i in range(0, length):
          val2 = household_objects_database_msgs.msg.DatabaseModelPose()
          start = end
          end += 4
          (val2.model_id,) = _struct_i.unpack(str[start:end])
          _v27 = val2.pose
          _v28 = _v27.header
          start = end
          end += 4
          (_v28.seq,) = _struct_I.unpack(str[start:end])
          _v29 = _v28.stamp
          _x = _v29
          start = end
          end += 8
          (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            _v28.frame_id = str[start:end].decode('utf-8')
          else:
            _v28.frame_id = str[start:end]
          _v30 = _v27.pose
          _v31 = _v30.position
          _x = _v31
          start = end
          end += 24
          (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
          _v32 = _v30.orientation
          _x = _v32
          start = end
          end += 32
          (_x.x, _x.y, _x.z, _x.w,) = _struct_4d.unpack(str[start:end])
          start = end
          end += 4
          (val2.confidence,) = _struct_f.unpack(str[start:end])
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val2.detector_name = str[start:end].decode('utf-8')
          else:
            val2.detector_name = str[start:end]
          val1.model_list.append(val2)
        self.detection_result.models.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      pattern = '<%si'%length
      start = end
      end += struct.calcsize(pattern)
      self.detection_result.cluster_model_indices = numpy.frombuffer(str[start:end], dtype=numpy.int32, count=length)
      _x = self
      start = end
      end += 6
      (_x.detection_result.result, _x.reset_collision_models, _x.reset_attached_models,) = _struct_i2B.unpack(str[start:end])
      self.reset_collision_models = bool(self.reset_collision_models)
      self.reset_attached_models = bool(self.reset_attached_models)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.desired_frame = str[start:end].decode('utf-8')
      else:
        self.desired_frame = str[start:end]
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e) #most likely buffer underfill

_struct_I = genpy.struct_I
_struct_i2B = struct.Struct("<i2B")
_struct_f = struct.Struct("<f")
_struct_7d4fb = struct.Struct("<7d4fb")
_struct_2I = struct.Struct("<2I")
_struct_i = struct.Struct("<i")
_struct_3I = struct.Struct("<3I")
_struct_4d = struct.Struct("<4d")
_struct_3f = struct.Struct("<3f")
_struct_3d = struct.Struct("<3d")
"""autogenerated by genpy from tabletop_collision_map_processing/TabletopCollisionMapProcessingResponse.msg. Do not edit."""
import sys
python3 = True if sys.hexversion > 0x03000000 else False
import genpy
import struct

import geometry_msgs.msg
import sensor_msgs.msg
import std_msgs.msg
import object_manipulation_msgs.msg
import household_objects_database_msgs.msg

class TabletopCollisionMapProcessingResponse(genpy.Message):
  _md5sum = "684fb6e369cb671a9c4149f683c75e88"
  _type = "tabletop_collision_map_processing/TabletopCollisionMapProcessingResponse"
  _has_header = False #flag to mark the presence of a Header object
  _full_text = """

object_manipulation_msgs/GraspableObject[] graspable_objects



string[] collision_object_names


string collision_support_surface_name


================================================================================
MSG: object_manipulation_msgs/GraspableObject
# an object that the object_manipulator can work on

# a graspable object can be represented in multiple ways. This message
# can contain all of them. Which one is actually used is up to the receiver
# of this message. When adding new representations, one must be careful that
# they have reasonable lightweight defaults indicating that that particular
# representation is not available.

# the tf frame to be used as a reference frame when combining information from
# the different representations below
string reference_frame_id

# potential recognition results from a database of models
# all poses are relative to the object reference pose
household_objects_database_msgs/DatabaseModelPose[] potential_models

# the point cloud itself
sensor_msgs/PointCloud cluster

# a region of a PointCloud2 of interest
object_manipulation_msgs/SceneRegion region

# the name that this object has in the collision environment
string collision_name
================================================================================
MSG: household_objects_database_msgs/DatabaseModelPose
# Informs that a specific model from the Model Database has been 
# identified at a certain location

# the database id of the model
int32 model_id

# the pose that it can be found in
geometry_msgs/PoseStamped pose

# a measure of the confidence level in this detection result
float32 confidence

# the name of the object detector that generated this detection result
string detector_name

================================================================================
MSG: geometry_msgs/PoseStamped
# A Pose with reference coordinate frame and timestamp
Header header
Pose pose

================================================================================
MSG: std_msgs/Header
# Standard metadata for higher-level stamped data types.
# This is generally used to communicate timestamped data 
# in a particular coordinate frame.
# 
# sequence ID: consecutively increasing ID 
uint32 seq
#Two-integer timestamp that is expressed as:
# * stamp.secs: seconds (stamp_secs) since epoch
# * stamp.nsecs: nanoseconds since stamp_secs
# time-handling sugar is provided by the client library
time stamp
#Frame this data is associated with
# 0: no frame
# 1: global frame
string frame_id

================================================================================
MSG: geometry_msgs/Pose
# A representation of pose in free space, composed of postion and orientation. 
Point position
Quaternion orientation

================================================================================
MSG: geometry_msgs/Point
# This contains the position of a point in free space
float64 x
float64 y
float64 z

================================================================================
MSG: geometry_msgs/Quaternion
# This represents an orientation in free space in quaternion form.

float64 x
float64 y
float64 z
float64 w

================================================================================
MSG: sensor_msgs/PointCloud
# This message holds a collection of 3d points, plus optional additional
# information about each point.

# Time of sensor data acquisition, coordinate frame ID.
Header header

# Array of 3d points. Each Point32 should be interpreted as a 3d point
# in the frame given in the header.
geometry_msgs/Point32[] points

# Each channel should have the same number of elements as points array,
# and the data in each channel should correspond 1:1 with each point.
# Channel names in common practice are listed in ChannelFloat32.msg.
ChannelFloat32[] channels

================================================================================
MSG: geometry_msgs/Point32
# This contains the position of a point in free space(with 32 bits of precision).
# It is recommeded to use Point wherever possible instead of Point32.  
# 
# This recommendation is to promote interoperability.  
#
# This message is designed to take up less space when sending
# lots of points at once, as in the case of a PointCloud.  

float32 x
float32 y
float32 z
================================================================================
MSG: sensor_msgs/ChannelFloat32
# This message is used by the PointCloud message to hold optional data
# associated with each point in the cloud. The length of the values
# array should be the same as the length of the points array in the
# PointCloud, and each value should be associated with the corresponding
# point.

# Channel names in existing practice include:
#   "u", "v" - row and column (respectively) in the left stereo image.
#              This is opposite to usual conventions but remains for
#              historical reasons. The newer PointCloud2 message has no
#              such problem.
#   "rgb" - For point clouds produced by color stereo cameras. uint8
#           (R,G,B) values packed into the least significant 24 bits,
#           in order.
#   "intensity" - laser or pixel intensity.
#   "distance"

# The channel name should give semantics of the channel (e.g.
# "intensity" instead of "value").
string name

# The values array should be 1-1 with the elements of the associated
# PointCloud.
float32[] values

================================================================================
MSG: object_manipulation_msgs/SceneRegion
# Point cloud
sensor_msgs/PointCloud2 cloud

# Indices for the region of interest
int32[] mask

# One of the corresponding 2D images, if applicable
sensor_msgs/Image image

# The disparity image, if applicable
sensor_msgs/Image disparity_image

# Camera info for the camera that took the image
sensor_msgs/CameraInfo cam_info

# a 3D region of interest for grasp planning
geometry_msgs/PoseStamped  roi_box_pose
geometry_msgs/Vector3 	   roi_box_dims

================================================================================
MSG: sensor_msgs/PointCloud2
# This message holds a collection of N-dimensional points, which may
# contain additional information such as normals, intensity, etc. The
# point data is stored as a binary blob, its layout described by the
# contents of the "fields" array.

# The point cloud data may be organized 2d (image-like) or 1d
# (unordered). Point clouds organized as 2d images may be produced by
# camera depth sensors such as stereo or time-of-flight.

# Time of sensor data acquisition, and the coordinate frame ID (for 3d
# points).
Header header

# 2D structure of the point cloud. If the cloud is unordered, height is
# 1 and width is the length of the point cloud.
uint32 height
uint32 width

# Describes the channels and their layout in the binary data blob.
PointField[] fields

bool    is_bigendian # Is this data bigendian?
uint32  point_step   # Length of a point in bytes
uint32  row_step     # Length of a row in bytes
uint8[] data         # Actual point data, size is (row_step*height)

bool is_dense        # True if there are no invalid points

================================================================================
MSG: sensor_msgs/PointField
# This message holds the description of one point entry in the
# PointCloud2 message format.
uint8 INT8    = 1
uint8 UINT8   = 2
uint8 INT16   = 3
uint8 UINT16  = 4
uint8 INT32   = 5
uint8 UINT32  = 6
uint8 FLOAT32 = 7
uint8 FLOAT64 = 8

string name      # Name of field
uint32 offset    # Offset from start of point struct
uint8  datatype  # Datatype enumeration, see above
uint32 count     # How many elements in the field

================================================================================
MSG: sensor_msgs/Image
# This message contains an uncompressed image
# (0, 0) is at top-left corner of image
#

Header header        # Header timestamp should be acquisition time of image
                     # Header frame_id should be optical frame of camera
                     # origin of frame should be optical center of cameara
                     # +x should point to the right in the image
                     # +y should point down in the image
                     # +z should point into to plane of the image
                     # If the frame_id here and the frame_id of the CameraInfo
                     # message associated with the image conflict
                     # the behavior is undefined

uint32 height         # image height, that is, number of rows
uint32 width          # image width, that is, number of columns

# The legal values for encoding are in file src/image_encodings.cpp
# If you want to standardize a new string format, join
# ros-users@lists.sourceforge.net and send an email proposing a new encoding.

string encoding       # Encoding of pixels -- channel meaning, ordering, size
                      # taken from the list of strings in include/sensor_msgs/image_encodings.h

uint8 is_bigendian    # is this data bigendian?
uint32 step           # Full row length in bytes
uint8[] data          # actual matrix data, size is (step * rows)

================================================================================
MSG: sensor_msgs/CameraInfo
# This message defines meta information for a camera. It should be in a
# camera namespace on topic "camera_info" and accompanied by up to five
# image topics named:
#
#   image_raw - raw data from the camera driver, possibly Bayer encoded
#   image            - monochrome, distorted
#   image_color      - color, distorted
#   image_rect       - monochrome, rectified
#   image_rect_color - color, rectified
#
# The image_pipeline contains packages (image_proc, stereo_image_proc)
# for producing the four processed image topics from image_raw and
# camera_info. The meaning of the camera parameters are described in
# detail at http://www.ros.org/wiki/image_pipeline/CameraInfo.
#
# The image_geometry package provides a user-friendly interface to
# common operations using this meta information. If you want to, e.g.,
# project a 3d point into image coordinates, we strongly recommend
# using image_geometry.
#
# If the camera is uncalibrated, the matrices D, K, R, P should be left
# zeroed out. In particular, clients may assume that K[0] == 0.0
# indicates an uncalibrated camera.

#######################################################################
#                     Image acquisition info                          #
#######################################################################

# Time of image acquisition, camera coordinate frame ID
Header header    # Header timestamp should be acquisition time of image
                 # Header frame_id should be optical frame of camera
                 # origin of frame should be optical center of camera
                 # +x should point to the right in the image
                 # +y should point down in the image
                 # +z should point into the plane of the image


#######################################################################
#                      Calibration Parameters                         #
#######################################################################
# These are fixed during camera calibration. Their values will be the #
# same in all messages until the camera is recalibrated. Note that    #
# self-calibrating systems may "recalibrate" frequently.              #
#                                                                     #
# The internal parameters can be used to warp a raw (distorted) image #
# to:                                                                 #
#   1. An undistorted image (requires D and K)                        #
#   2. A rectified image (requires D, K, R)                           #
# The projection matrix P projects 3D points into the rectified image.#
#######################################################################

# The image dimensions with which the camera was calibrated. Normally
# this will be the full camera resolution in pixels.
uint32 height
uint32 width

# The distortion model used. Supported models are listed in
# sensor_msgs/distortion_models.h. For most cameras, "plumb_bob" - a
# simple model of radial and tangential distortion - is sufficent.
string distortion_model

# The distortion parameters, size depending on the distortion model.
# For "plumb_bob", the 5 parameters are: (k1, k2, t1, t2, k3).
float64[] D

# Intrinsic camera matrix for the raw (distorted) images.
#     [fx  0 cx]
# K = [ 0 fy cy]
#     [ 0  0  1]
# Projects 3D points in the camera coordinate frame to 2D pixel
# coordinates using the focal lengths (fx, fy) and principal point
# (cx, cy).
float64[9]  K # 3x3 row-major matrix

# Rectification matrix (stereo cameras only)
# A rotation matrix aligning the camera coordinate system to the ideal
# stereo image plane so that epipolar lines in both stereo images are
# parallel.
float64[9]  R # 3x3 row-major matrix

# Projection/camera matrix
#     [fx'  0  cx' Tx]
# P = [ 0  fy' cy' Ty]
#     [ 0   0   1   0]
# By convention, this matrix specifies the intrinsic (camera) matrix
#  of the processed (rectified) image. That is, the left 3x3 portion
#  is the normal camera intrinsic matrix for the rectified image.
# It projects 3D points in the camera coordinate frame to 2D pixel
#  coordinates using the focal lengths (fx', fy') and principal point
#  (cx', cy') - these may differ from the values in K.
# For monocular cameras, Tx = Ty = 0. Normally, monocular cameras will
#  also have R = the identity and P[1:3,1:3] = K.
# For a stereo pair, the fourth column [Tx Ty 0]' is related to the
#  position of the optical center of the second camera in the first
#  camera's frame. We assume Tz = 0 so both cameras are in the same
#  stereo image plane. The first camera always has Tx = Ty = 0. For
#  the right (second) camera of a horizontal stereo pair, Ty = 0 and
#  Tx = -fx' * B, where B is the baseline between the cameras.
# Given a 3D point [X Y Z]', the projection (x, y) of the point onto
#  the rectified image is given by:
#  [u v w]' = P * [X Y Z 1]'
#         x = u / w
#         y = v / w
#  This holds for both images of a stereo pair.
float64[12] P # 3x4 row-major matrix


#######################################################################
#                      Operational Parameters                         #
#######################################################################
# These define the image region actually captured by the camera       #
# driver. Although they affect the geometry of the output image, they #
# may be changed freely without recalibrating the camera.             #
#######################################################################

# Binning refers here to any camera setting which combines rectangular
#  neighborhoods of pixels into larger "super-pixels." It reduces the
#  resolution of the output image to
#  (width / binning_x) x (height / binning_y).
# The default values binning_x = binning_y = 0 is considered the same
#  as binning_x = binning_y = 1 (no subsampling).
uint32 binning_x
uint32 binning_y

# Region of interest (subwindow of full camera resolution), given in
#  full resolution (unbinned) image coordinates. A particular ROI
#  always denotes the same window of pixels on the camera sensor,
#  regardless of binning settings.
# The default setting of roi (all values 0) is considered the same as
#  full resolution (roi.width = width, roi.height = height).
RegionOfInterest roi

================================================================================
MSG: sensor_msgs/RegionOfInterest
# This message is used to specify a region of interest within an image.
#
# When used to specify the ROI setting of the camera when the image was
# taken, the height and width fields should either match the height and
# width fields for the associated image; or height = width = 0
# indicates that the full resolution image was captured.

uint32 x_offset  # Leftmost pixel of the ROI
                 # (0 if the ROI includes the left edge of the image)
uint32 y_offset  # Topmost pixel of the ROI
                 # (0 if the ROI includes the top edge of the image)
uint32 height    # Height of ROI
uint32 width     # Width of ROI

# True if a distinct rectified ROI should be calculated from the "raw"
# ROI in this message. Typically this should be False if the full image
# is captured (ROI not used), and True if a subwindow is captured (ROI
# used).
bool do_rectify

================================================================================
MSG: geometry_msgs/Vector3
# This represents a vector in free space. 

float64 x
float64 y
float64 z
"""
  __slots__ = ['graspable_objects','collision_object_names','collision_support_surface_name']
  _slot_types = ['object_manipulation_msgs/GraspableObject[]','string[]','string']

  def __init__(self, *args, **kwds):
    """
    Constructor. Any message fields that are implicitly/explicitly
    set to None will be assigned a default value. The recommend
    use is keyword arguments as this is more robust to future message
    changes.  You cannot mix in-order arguments and keyword arguments.

    The available fields are:
       graspable_objects,collision_object_names,collision_support_surface_name

    :param args: complete set of field values, in .msg order
    :param kwds: use keyword arguments corresponding to message field names
    to set specific fields.
    """
    if args or kwds:
      super(TabletopCollisionMapProcessingResponse, self).__init__(*args, **kwds)
      #message fields cannot be None, assign default values for those that are
      if self.graspable_objects is None:
        self.graspable_objects = []
      if self.collision_object_names is None:
        self.collision_object_names = []
      if self.collision_support_surface_name is None:
        self.collision_support_surface_name = ''
    else:
      self.graspable_objects = []
      self.collision_object_names = []
      self.collision_support_surface_name = ''

  def _get_types(self):
    """
    internal API method
    """
    return self._slot_types

  def serialize(self, buff):
    """
    serialize message into buffer
    :param buff: buffer, ``StringIO``
    """
    try:
      length = len(self.graspable_objects)
      buff.write(_struct_I.pack(length))
      for val1 in self.graspable_objects:
        _x = val1.reference_frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        length = len(val1.potential_models)
        buff.write(_struct_I.pack(length))
        for val2 in val1.potential_models:
          buff.write(_struct_i.pack(val2.model_id))
          _v33 = val2.pose
          _v34 = _v33.header
          buff.write(_struct_I.pack(_v34.seq))
          _v35 = _v34.stamp
          _x = _v35
          buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
          _x = _v34.frame_id
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          _v36 = _v33.pose
          _v37 = _v36.position
          _x = _v37
          buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
          _v38 = _v36.orientation
          _x = _v38
          buff.write(_struct_4d.pack(_x.x, _x.y, _x.z, _x.w))
          buff.write(_struct_f.pack(val2.confidence))
          _x = val2.detector_name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
        _v39 = val1.cluster
        _v40 = _v39.header
        buff.write(_struct_I.pack(_v40.seq))
        _v41 = _v40.stamp
        _x = _v41
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v40.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        length = len(_v39.points)
        buff.write(_struct_I.pack(length))
        for val3 in _v39.points:
          _x = val3
          buff.write(_struct_3f.pack(_x.x, _x.y, _x.z))
        length = len(_v39.channels)
        buff.write(_struct_I.pack(length))
        for val3 in _v39.channels:
          _x = val3.name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          length = len(val3.values)
          buff.write(_struct_I.pack(length))
          pattern = '<%sf'%length
          buff.write(struct.pack(pattern, *val3.values))
        _v42 = val1.region
        _v43 = _v42.cloud
        _v44 = _v43.header
        buff.write(_struct_I.pack(_v44.seq))
        _v45 = _v44.stamp
        _x = _v45
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v44.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v43
        buff.write(_struct_2I.pack(_x.height, _x.width))
        length = len(_v43.fields)
        buff.write(_struct_I.pack(length))
        for val4 in _v43.fields:
          _x = val4.name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          _x = val4
          buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
        _x = _v43
        buff.write(_struct_B2I.pack(_x.is_bigendian, _x.point_step, _x.row_step))
        _x = _v43.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.pack('<I%sB'%length, length, *_x))
        else:
          buff.write(struct.pack('<I%ss'%length, length, _x))
        buff.write(_struct_B.pack(_v43.is_dense))
        length = len(_v42.mask)
        buff.write(_struct_I.pack(length))
        pattern = '<%si'%length
        buff.write(struct.pack(pattern, *_v42.mask))
        _v46 = _v42.image
        _v47 = _v46.header
        buff.write(_struct_I.pack(_v47.seq))
        _v48 = _v47.stamp
        _x = _v48
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v47.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v46
        buff.write(_struct_2I.pack(_x.height, _x.width))
        _x = _v46.encoding
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v46
        buff.write(_struct_BI.pack(_x.is_bigendian, _x.step))
        _x = _v46.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.pack('<I%sB'%length, length, *_x))
        else:
          buff.write(struct.pack('<I%ss'%length, length, _x))
        _v49 = _v42.disparity_image
        _v50 = _v49.header
        buff.write(_struct_I.pack(_v50.seq))
        _v51 = _v50.stamp
        _x = _v51
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v50.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v49
        buff.write(_struct_2I.pack(_x.height, _x.width))
        _x = _v49.encoding
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v49
        buff.write(_struct_BI.pack(_x.is_bigendian, _x.step))
        _x = _v49.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.pack('<I%sB'%length, length, *_x))
        else:
          buff.write(struct.pack('<I%ss'%length, length, _x))
        _v52 = _v42.cam_info
        _v53 = _v52.header
        buff.write(_struct_I.pack(_v53.seq))
        _v54 = _v53.stamp
        _x = _v54
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v53.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v52
        buff.write(_struct_2I.pack(_x.height, _x.width))
        _x = _v52.distortion_model
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        length = len(_v52.D)
        buff.write(_struct_I.pack(length))
        pattern = '<%sd'%length
        buff.write(struct.pack(pattern, *_v52.D))
        buff.write(_struct_9d.pack(*_v52.K))
        buff.write(_struct_9d.pack(*_v52.R))
        buff.write(_struct_12d.pack(*_v52.P))
        _x = _v52
        buff.write(_struct_2I.pack(_x.binning_x, _x.binning_y))
        _v55 = _v52.roi
        _x = _v55
        buff.write(_struct_4IB.pack(_x.x_offset, _x.y_offset, _x.height, _x.width, _x.do_rectify))
        _v56 = _v42.roi_box_pose
        _v57 = _v56.header
        buff.write(_struct_I.pack(_v57.seq))
        _v58 = _v57.stamp
        _x = _v58
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v57.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _v59 = _v56.pose
        _v60 = _v59.position
        _x = _v60
        buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
        _v61 = _v59.orientation
        _x = _v61
        buff.write(_struct_4d.pack(_x.x, _x.y, _x.z, _x.w))
        _v62 = _v42.roi_box_dims
        _x = _v62
        buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
        _x = val1.collision_name
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
      length = len(self.collision_object_names)
      buff.write(_struct_I.pack(length))
      for val1 in self.collision_object_names:
        length = len(val1)
        if python3 or type(val1) == unicode:
          val1 = val1.encode('utf-8')
          length = len(val1)
        buff.write(struct.pack('<I%ss'%length, length, val1))
      _x = self.collision_support_surface_name
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x))
    except struct.error as se: self._check_types(se)
    except TypeError as te: self._check_types(te)

  def deserialize(self, str):
    """
    unpack serialized message in str into this message instance
    :param str: byte array of serialized message, ``str``
    """
    try:
      if self.graspable_objects is None:
        self.graspable_objects = None
      end = 0
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.graspable_objects = []
      for i in range(0, length):
        val1 = object_manipulation_msgs.msg.GraspableObject()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1.reference_frame_id = str[start:end].decode('utf-8')
        else:
          val1.reference_frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.potential_models = []
        for i in range(0, length):
          val2 = household_objects_database_msgs.msg.DatabaseModelPose()
          start = end
          end += 4
          (val2.model_id,) = _struct_i.unpack(str[start:end])
          _v63 = val2.pose
          _v64 = _v63.header
          start = end
          end += 4
          (_v64.seq,) = _struct_I.unpack(str[start:end])
          _v65 = _v64.stamp
          _x = _v65
          start = end
          end += 8
          (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            _v64.frame_id = str[start:end].decode('utf-8')
          else:
            _v64.frame_id = str[start:end]
          _v66 = _v63.pose
          _v67 = _v66.position
          _x = _v67
          start = end
          end += 24
          (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
          _v68 = _v66.orientation
          _x = _v68
          start = end
          end += 32
          (_x.x, _x.y, _x.z, _x.w,) = _struct_4d.unpack(str[start:end])
          start = end
          end += 4
          (val2.confidence,) = _struct_f.unpack(str[start:end])
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val2.detector_name = str[start:end].decode('utf-8')
          else:
            val2.detector_name = str[start:end]
          val1.potential_models.append(val2)
        _v69 = val1.cluster
        _v70 = _v69.header
        start = end
        end += 4
        (_v70.seq,) = _struct_I.unpack(str[start:end])
        _v71 = _v70.stamp
        _x = _v71
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v70.frame_id = str[start:end].decode('utf-8')
        else:
          _v70.frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        _v69.points = []
        for i in range(0, length):
          val3 = geometry_msgs.msg.Point32()
          _x = val3
          start = end
          end += 12
          (_x.x, _x.y, _x.z,) = _struct_3f.unpack(str[start:end])
          _v69.points.append(val3)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        _v69.channels = []
        for i in range(0, length):
          val3 = sensor_msgs.msg.ChannelFloat32()
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val3.name = str[start:end].decode('utf-8')
          else:
            val3.name = str[start:end]
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          pattern = '<%sf'%length
          start = end
          end += struct.calcsize(pattern)
          val3.values = struct.unpack(pattern, str[start:end])
          _v69.channels.append(val3)
        _v72 = val1.region
        _v73 = _v72.cloud
        _v74 = _v73.header
        start = end
        end += 4
        (_v74.seq,) = _struct_I.unpack(str[start:end])
        _v75 = _v74.stamp
        _x = _v75
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v74.frame_id = str[start:end].decode('utf-8')
        else:
          _v74.frame_id = str[start:end]
        _x = _v73
        start = end
        end += 8
        (_x.height, _x.width,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        _v73.fields = []
        for i in range(0, length):
          val4 = sensor_msgs.msg.PointField()
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val4.name = str[start:end].decode('utf-8')
          else:
            val4.name = str[start:end]
          _x = val4
          start = end
          end += 9
          (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
          _v73.fields.append(val4)
        _x = _v73
        start = end
        end += 9
        (_x.is_bigendian, _x.point_step, _x.row_step,) = _struct_B2I.unpack(str[start:end])
        _v73.is_bigendian = bool(_v73.is_bigendian)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v73.data = str[start:end].decode('utf-8')
        else:
          _v73.data = str[start:end]
        start = end
        end += 1
        (_v73.is_dense,) = _struct_B.unpack(str[start:end])
        _v73.is_dense = bool(_v73.is_dense)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        pattern = '<%si'%length
        start = end
        end += struct.calcsize(pattern)
        _v72.mask = struct.unpack(pattern, str[start:end])
        _v76 = _v72.image
        _v77 = _v76.header
        start = end
        end += 4
        (_v77.seq,) = _struct_I.unpack(str[start:end])
        _v78 = _v77.stamp
        _x = _v78
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v77.frame_id = str[start:end].decode('utf-8')
        else:
          _v77.frame_id = str[start:end]
        _x = _v76
        start = end
        end += 8
        (_x.height, _x.width,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v76.encoding = str[start:end].decode('utf-8')
        else:
          _v76.encoding = str[start:end]
        _x = _v76
        start = end
        end += 5
        (_x.is_bigendian, _x.step,) = _struct_BI.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v76.data = str[start:end].decode('utf-8')
        else:
          _v76.data = str[start:end]
        _v79 = _v72.disparity_image
        _v80 = _v79.header
        start = end
        end += 4
        (_v80.seq,) = _struct_I.unpack(str[start:end])
        _v81 = _v80.stamp
        _x = _v81
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v80.frame_id = str[start:end].decode('utf-8')
        else:
          _v80.frame_id = str[start:end]
        _x = _v79
        start = end
        end += 8
        (_x.height, _x.width,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v79.encoding = str[start:end].decode('utf-8')
        else:
          _v79.encoding = str[start:end]
        _x = _v79
        start = end
        end += 5
        (_x.is_bigendian, _x.step,) = _struct_BI.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v79.data = str[start:end].decode('utf-8')
        else:
          _v79.data = str[start:end]
        _v82 = _v72.cam_info
        _v83 = _v82.header
        start = end
        end += 4
        (_v83.seq,) = _struct_I.unpack(str[start:end])
        _v84 = _v83.stamp
        _x = _v84
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v83.frame_id = str[start:end].decode('utf-8')
        else:
          _v83.frame_id = str[start:end]
        _x = _v82
        start = end
        end += 8
        (_x.height, _x.width,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v82.distortion_model = str[start:end].decode('utf-8')
        else:
          _v82.distortion_model = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        pattern = '<%sd'%length
        start = end
        end += struct.calcsize(pattern)
        _v82.D = struct.unpack(pattern, str[start:end])
        start = end
        end += 72
        _v82.K = _struct_9d.unpack(str[start:end])
        start = end
        end += 72
        _v82.R = _struct_9d.unpack(str[start:end])
        start = end
        end += 96
        _v82.P = _struct_12d.unpack(str[start:end])
        _x = _v82
        start = end
        end += 8
        (_x.binning_x, _x.binning_y,) = _struct_2I.unpack(str[start:end])
        _v85 = _v82.roi
        _x = _v85
        start = end
        end += 17
        (_x.x_offset, _x.y_offset, _x.height, _x.width, _x.do_rectify,) = _struct_4IB.unpack(str[start:end])
        _v85.do_rectify = bool(_v85.do_rectify)
        _v86 = _v72.roi_box_pose
        _v87 = _v86.header
        start = end
        end += 4
        (_v87.seq,) = _struct_I.unpack(str[start:end])
        _v88 = _v87.stamp
        _x = _v88
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v87.frame_id = str[start:end].decode('utf-8')
        else:
          _v87.frame_id = str[start:end]
        _v89 = _v86.pose
        _v90 = _v89.position
        _x = _v90
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
        _v91 = _v89.orientation
        _x = _v91
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _struct_4d.unpack(str[start:end])
        _v92 = _v72.roi_box_dims
        _x = _v92
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1.collision_name = str[start:end].decode('utf-8')
        else:
          val1.collision_name = str[start:end]
        self.graspable_objects.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.collision_object_names = []
      for i in range(0, length):
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1 = str[start:end].decode('utf-8')
        else:
          val1 = str[start:end]
        self.collision_object_names.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.collision_support_surface_name = str[start:end].decode('utf-8')
      else:
        self.collision_support_surface_name = str[start:end]
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e) #most likely buffer underfill


  def serialize_numpy(self, buff, numpy):
    """
    serialize message with numpy array types into buffer
    :param buff: buffer, ``StringIO``
    :param numpy: numpy python module
    """
    try:
      length = len(self.graspable_objects)
      buff.write(_struct_I.pack(length))
      for val1 in self.graspable_objects:
        _x = val1.reference_frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        length = len(val1.potential_models)
        buff.write(_struct_I.pack(length))
        for val2 in val1.potential_models:
          buff.write(_struct_i.pack(val2.model_id))
          _v93 = val2.pose
          _v94 = _v93.header
          buff.write(_struct_I.pack(_v94.seq))
          _v95 = _v94.stamp
          _x = _v95
          buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
          _x = _v94.frame_id
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          _v96 = _v93.pose
          _v97 = _v96.position
          _x = _v97
          buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
          _v98 = _v96.orientation
          _x = _v98
          buff.write(_struct_4d.pack(_x.x, _x.y, _x.z, _x.w))
          buff.write(_struct_f.pack(val2.confidence))
          _x = val2.detector_name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
        _v99 = val1.cluster
        _v100 = _v99.header
        buff.write(_struct_I.pack(_v100.seq))
        _v101 = _v100.stamp
        _x = _v101
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v100.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        length = len(_v99.points)
        buff.write(_struct_I.pack(length))
        for val3 in _v99.points:
          _x = val3
          buff.write(_struct_3f.pack(_x.x, _x.y, _x.z))
        length = len(_v99.channels)
        buff.write(_struct_I.pack(length))
        for val3 in _v99.channels:
          _x = val3.name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          length = len(val3.values)
          buff.write(_struct_I.pack(length))
          pattern = '<%sf'%length
          buff.write(val3.values.tostring())
        _v102 = val1.region
        _v103 = _v102.cloud
        _v104 = _v103.header
        buff.write(_struct_I.pack(_v104.seq))
        _v105 = _v104.stamp
        _x = _v105
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v104.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v103
        buff.write(_struct_2I.pack(_x.height, _x.width))
        length = len(_v103.fields)
        buff.write(_struct_I.pack(length))
        for val4 in _v103.fields:
          _x = val4.name
          length = len(_x)
          if python3 or type(_x) == unicode:
            _x = _x.encode('utf-8')
            length = len(_x)
          buff.write(struct.pack('<I%ss'%length, length, _x))
          _x = val4
          buff.write(_struct_IBI.pack(_x.offset, _x.datatype, _x.count))
        _x = _v103
        buff.write(_struct_B2I.pack(_x.is_bigendian, _x.point_step, _x.row_step))
        _x = _v103.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.pack('<I%sB'%length, length, *_x))
        else:
          buff.write(struct.pack('<I%ss'%length, length, _x))
        buff.write(_struct_B.pack(_v103.is_dense))
        length = len(_v102.mask)
        buff.write(_struct_I.pack(length))
        pattern = '<%si'%length
        buff.write(_v102.mask.tostring())
        _v106 = _v102.image
        _v107 = _v106.header
        buff.write(_struct_I.pack(_v107.seq))
        _v108 = _v107.stamp
        _x = _v108
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v107.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v106
        buff.write(_struct_2I.pack(_x.height, _x.width))
        _x = _v106.encoding
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v106
        buff.write(_struct_BI.pack(_x.is_bigendian, _x.step))
        _x = _v106.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.pack('<I%sB'%length, length, *_x))
        else:
          buff.write(struct.pack('<I%ss'%length, length, _x))
        _v109 = _v102.disparity_image
        _v110 = _v109.header
        buff.write(_struct_I.pack(_v110.seq))
        _v111 = _v110.stamp
        _x = _v111
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v110.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v109
        buff.write(_struct_2I.pack(_x.height, _x.width))
        _x = _v109.encoding
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v109
        buff.write(_struct_BI.pack(_x.is_bigendian, _x.step))
        _x = _v109.data
        length = len(_x)
        # - if encoded as a list instead, serialize as bytes instead of string
        if type(_x) in [list, tuple]:
          buff.write(struct.pack('<I%sB'%length, length, *_x))
        else:
          buff.write(struct.pack('<I%ss'%length, length, _x))
        _v112 = _v102.cam_info
        _v113 = _v112.header
        buff.write(_struct_I.pack(_v113.seq))
        _v114 = _v113.stamp
        _x = _v114
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v113.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _x = _v112
        buff.write(_struct_2I.pack(_x.height, _x.width))
        _x = _v112.distortion_model
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        length = len(_v112.D)
        buff.write(_struct_I.pack(length))
        pattern = '<%sd'%length
        buff.write(_v112.D.tostring())
        buff.write(_v112.K.tostring())
        buff.write(_v112.R.tostring())
        buff.write(_v112.P.tostring())
        _x = _v112
        buff.write(_struct_2I.pack(_x.binning_x, _x.binning_y))
        _v115 = _v112.roi
        _x = _v115
        buff.write(_struct_4IB.pack(_x.x_offset, _x.y_offset, _x.height, _x.width, _x.do_rectify))
        _v116 = _v102.roi_box_pose
        _v117 = _v116.header
        buff.write(_struct_I.pack(_v117.seq))
        _v118 = _v117.stamp
        _x = _v118
        buff.write(_struct_2I.pack(_x.secs, _x.nsecs))
        _x = _v117.frame_id
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
        _v119 = _v116.pose
        _v120 = _v119.position
        _x = _v120
        buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
        _v121 = _v119.orientation
        _x = _v121
        buff.write(_struct_4d.pack(_x.x, _x.y, _x.z, _x.w))
        _v122 = _v102.roi_box_dims
        _x = _v122
        buff.write(_struct_3d.pack(_x.x, _x.y, _x.z))
        _x = val1.collision_name
        length = len(_x)
        if python3 or type(_x) == unicode:
          _x = _x.encode('utf-8')
          length = len(_x)
        buff.write(struct.pack('<I%ss'%length, length, _x))
      length = len(self.collision_object_names)
      buff.write(_struct_I.pack(length))
      for val1 in self.collision_object_names:
        length = len(val1)
        if python3 or type(val1) == unicode:
          val1 = val1.encode('utf-8')
          length = len(val1)
        buff.write(struct.pack('<I%ss'%length, length, val1))
      _x = self.collision_support_surface_name
      length = len(_x)
      if python3 or type(_x) == unicode:
        _x = _x.encode('utf-8')
        length = len(_x)
      buff.write(struct.pack('<I%ss'%length, length, _x))
    except struct.error as se: self._check_types(se)
    except TypeError as te: self._check_types(te)

  def deserialize_numpy(self, str, numpy):
    """
    unpack serialized message in str into this message instance using numpy for array types
    :param str: byte array of serialized message, ``str``
    :param numpy: numpy python module
    """
    try:
      if self.graspable_objects is None:
        self.graspable_objects = None
      end = 0
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.graspable_objects = []
      for i in range(0, length):
        val1 = object_manipulation_msgs.msg.GraspableObject()
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1.reference_frame_id = str[start:end].decode('utf-8')
        else:
          val1.reference_frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        val1.potential_models = []
        for i in range(0, length):
          val2 = household_objects_database_msgs.msg.DatabaseModelPose()
          start = end
          end += 4
          (val2.model_id,) = _struct_i.unpack(str[start:end])
          _v123 = val2.pose
          _v124 = _v123.header
          start = end
          end += 4
          (_v124.seq,) = _struct_I.unpack(str[start:end])
          _v125 = _v124.stamp
          _x = _v125
          start = end
          end += 8
          (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            _v124.frame_id = str[start:end].decode('utf-8')
          else:
            _v124.frame_id = str[start:end]
          _v126 = _v123.pose
          _v127 = _v126.position
          _x = _v127
          start = end
          end += 24
          (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
          _v128 = _v126.orientation
          _x = _v128
          start = end
          end += 32
          (_x.x, _x.y, _x.z, _x.w,) = _struct_4d.unpack(str[start:end])
          start = end
          end += 4
          (val2.confidence,) = _struct_f.unpack(str[start:end])
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val2.detector_name = str[start:end].decode('utf-8')
          else:
            val2.detector_name = str[start:end]
          val1.potential_models.append(val2)
        _v129 = val1.cluster
        _v130 = _v129.header
        start = end
        end += 4
        (_v130.seq,) = _struct_I.unpack(str[start:end])
        _v131 = _v130.stamp
        _x = _v131
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v130.frame_id = str[start:end].decode('utf-8')
        else:
          _v130.frame_id = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        _v129.points = []
        for i in range(0, length):
          val3 = geometry_msgs.msg.Point32()
          _x = val3
          start = end
          end += 12
          (_x.x, _x.y, _x.z,) = _struct_3f.unpack(str[start:end])
          _v129.points.append(val3)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        _v129.channels = []
        for i in range(0, length):
          val3 = sensor_msgs.msg.ChannelFloat32()
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val3.name = str[start:end].decode('utf-8')
          else:
            val3.name = str[start:end]
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          pattern = '<%sf'%length
          start = end
          end += struct.calcsize(pattern)
          val3.values = numpy.frombuffer(str[start:end], dtype=numpy.float32, count=length)
          _v129.channels.append(val3)
        _v132 = val1.region
        _v133 = _v132.cloud
        _v134 = _v133.header
        start = end
        end += 4
        (_v134.seq,) = _struct_I.unpack(str[start:end])
        _v135 = _v134.stamp
        _x = _v135
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v134.frame_id = str[start:end].decode('utf-8')
        else:
          _v134.frame_id = str[start:end]
        _x = _v133
        start = end
        end += 8
        (_x.height, _x.width,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        _v133.fields = []
        for i in range(0, length):
          val4 = sensor_msgs.msg.PointField()
          start = end
          end += 4
          (length,) = _struct_I.unpack(str[start:end])
          start = end
          end += length
          if python3:
            val4.name = str[start:end].decode('utf-8')
          else:
            val4.name = str[start:end]
          _x = val4
          start = end
          end += 9
          (_x.offset, _x.datatype, _x.count,) = _struct_IBI.unpack(str[start:end])
          _v133.fields.append(val4)
        _x = _v133
        start = end
        end += 9
        (_x.is_bigendian, _x.point_step, _x.row_step,) = _struct_B2I.unpack(str[start:end])
        _v133.is_bigendian = bool(_v133.is_bigendian)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v133.data = str[start:end].decode('utf-8')
        else:
          _v133.data = str[start:end]
        start = end
        end += 1
        (_v133.is_dense,) = _struct_B.unpack(str[start:end])
        _v133.is_dense = bool(_v133.is_dense)
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        pattern = '<%si'%length
        start = end
        end += struct.calcsize(pattern)
        _v132.mask = numpy.frombuffer(str[start:end], dtype=numpy.int32, count=length)
        _v136 = _v132.image
        _v137 = _v136.header
        start = end
        end += 4
        (_v137.seq,) = _struct_I.unpack(str[start:end])
        _v138 = _v137.stamp
        _x = _v138
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v137.frame_id = str[start:end].decode('utf-8')
        else:
          _v137.frame_id = str[start:end]
        _x = _v136
        start = end
        end += 8
        (_x.height, _x.width,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v136.encoding = str[start:end].decode('utf-8')
        else:
          _v136.encoding = str[start:end]
        _x = _v136
        start = end
        end += 5
        (_x.is_bigendian, _x.step,) = _struct_BI.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v136.data = str[start:end].decode('utf-8')
        else:
          _v136.data = str[start:end]
        _v139 = _v132.disparity_image
        _v140 = _v139.header
        start = end
        end += 4
        (_v140.seq,) = _struct_I.unpack(str[start:end])
        _v141 = _v140.stamp
        _x = _v141
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v140.frame_id = str[start:end].decode('utf-8')
        else:
          _v140.frame_id = str[start:end]
        _x = _v139
        start = end
        end += 8
        (_x.height, _x.width,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v139.encoding = str[start:end].decode('utf-8')
        else:
          _v139.encoding = str[start:end]
        _x = _v139
        start = end
        end += 5
        (_x.is_bigendian, _x.step,) = _struct_BI.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v139.data = str[start:end].decode('utf-8')
        else:
          _v139.data = str[start:end]
        _v142 = _v132.cam_info
        _v143 = _v142.header
        start = end
        end += 4
        (_v143.seq,) = _struct_I.unpack(str[start:end])
        _v144 = _v143.stamp
        _x = _v144
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v143.frame_id = str[start:end].decode('utf-8')
        else:
          _v143.frame_id = str[start:end]
        _x = _v142
        start = end
        end += 8
        (_x.height, _x.width,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v142.distortion_model = str[start:end].decode('utf-8')
        else:
          _v142.distortion_model = str[start:end]
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        pattern = '<%sd'%length
        start = end
        end += struct.calcsize(pattern)
        _v142.D = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=length)
        start = end
        end += 72
        _v142.K = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=9)
        start = end
        end += 72
        _v142.R = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=9)
        start = end
        end += 96
        _v142.P = numpy.frombuffer(str[start:end], dtype=numpy.float64, count=12)
        _x = _v142
        start = end
        end += 8
        (_x.binning_x, _x.binning_y,) = _struct_2I.unpack(str[start:end])
        _v145 = _v142.roi
        _x = _v145
        start = end
        end += 17
        (_x.x_offset, _x.y_offset, _x.height, _x.width, _x.do_rectify,) = _struct_4IB.unpack(str[start:end])
        _v145.do_rectify = bool(_v145.do_rectify)
        _v146 = _v132.roi_box_pose
        _v147 = _v146.header
        start = end
        end += 4
        (_v147.seq,) = _struct_I.unpack(str[start:end])
        _v148 = _v147.stamp
        _x = _v148
        start = end
        end += 8
        (_x.secs, _x.nsecs,) = _struct_2I.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          _v147.frame_id = str[start:end].decode('utf-8')
        else:
          _v147.frame_id = str[start:end]
        _v149 = _v146.pose
        _v150 = _v149.position
        _x = _v150
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
        _v151 = _v149.orientation
        _x = _v151
        start = end
        end += 32
        (_x.x, _x.y, _x.z, _x.w,) = _struct_4d.unpack(str[start:end])
        _v152 = _v132.roi_box_dims
        _x = _v152
        start = end
        end += 24
        (_x.x, _x.y, _x.z,) = _struct_3d.unpack(str[start:end])
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1.collision_name = str[start:end].decode('utf-8')
        else:
          val1.collision_name = str[start:end]
        self.graspable_objects.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      self.collision_object_names = []
      for i in range(0, length):
        start = end
        end += 4
        (length,) = _struct_I.unpack(str[start:end])
        start = end
        end += length
        if python3:
          val1 = str[start:end].decode('utf-8')
        else:
          val1 = str[start:end]
        self.collision_object_names.append(val1)
      start = end
      end += 4
      (length,) = _struct_I.unpack(str[start:end])
      start = end
      end += length
      if python3:
        self.collision_support_surface_name = str[start:end].decode('utf-8')
      else:
        self.collision_support_surface_name = str[start:end]
      return self
    except struct.error as e:
      raise genpy.DeserializationError(e) #most likely buffer underfill

_struct_I = genpy.struct_I
_struct_IBI = struct.Struct("<IBI")
_struct_B = struct.Struct("<B")
_struct_12d = struct.Struct("<12d")
_struct_f = struct.Struct("<f")
_struct_i = struct.Struct("<i")
_struct_BI = struct.Struct("<BI")
_struct_3f = struct.Struct("<3f")
_struct_9d = struct.Struct("<9d")
_struct_B2I = struct.Struct("<B2I")
_struct_4d = struct.Struct("<4d")
_struct_2I = struct.Struct("<2I")
_struct_4IB = struct.Struct("<4IB")
_struct_3d = struct.Struct("<3d")
class TabletopCollisionMapProcessing(object):
  _type          = 'tabletop_collision_map_processing/TabletopCollisionMapProcessing'
  _md5sum = '58e439dda25eed20079051e6af1b5eaa'
  _request_class  = TabletopCollisionMapProcessingRequest
  _response_class = TabletopCollisionMapProcessingResponse
